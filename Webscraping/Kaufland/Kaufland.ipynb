{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec90b855",
   "metadata": {},
   "source": [
    "# Online Markplatz Kaufland<br>\n",
    "## Main Category ---> Lebensmittel & Gesundheit<br>\n",
    "### Max PageNumber ---> Any PageNumber<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8345c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0247cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Website Page https://www.kaufland.de/\n",
      "Total Number of Categories :  2\n",
      "Main Category :  https://www.kaufland.de/lebensmittel/\n",
      "Main Category Link :  https://www.kaufland.de/lebensmittel/\n",
      "Total Number of Sub-Categories within the Category : 55\n",
      "Sub-Category Link :  https://www.kaufland.de/tee/\n",
      "Total Number of Products in Page 1  is :  35\n",
      "Access to the Page Number :  2  link is : https://www.kaufland.de/category/2481/p2/\n",
      "Total Number of Products in Page 2  is :  35\n",
      "Access to the Page Number :  3  link is : https://www.kaufland.de/category/2481/p3/\n",
      "Total Number of Products in Page 3  is :  35\n",
      "Access to the Page Number :  4  link is : https://www.kaufland.de/category/2481/p4/\n",
      "Total Number of Products in Page 4  is :  35\n",
      "Error Due to PageNumber/Category....\n",
      "Sub-Category Link :  https://www.kaufland.de/loser-tee/\n",
      "Total Number of Products in Page 1  is :  35\n",
      "Sub-Category Link :  https://www.kaufland.de/teebeutel/\n",
      "Total Number of Products in Page 1  is :  35\n",
      "Sub-Category Link :  https://www.kaufland.de/kakao/\n",
      "Total Number of Products in Page 1  is :  34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "main_url = \"https://www.kaufland.de/\"\n",
    "print('Main Website Page', main_url)\n",
    "\n",
    "def request_to_kaufland(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.text, \"html.parser\")\n",
    "    except requests.RequestException as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def access_main_categories(categories_link):\n",
    "    print ('Total Number of Categories : ', len(categories_link))\n",
    "    try:\n",
    "        for i in range(len(categories_link)):   # len(categories_link)\n",
    "            print ('Main Category : ', categories_link[i])\n",
    "            print ('Main Category Link : ', categories_link[i])\n",
    "            categories_soup = request_to_kaufland(categories_link[i])\n",
    "            a_tag = categories_soup.find_all('a', class_='rd-link rd-link--navi-secondary rd-category-sublinks__sublink rd-category-sublinks__sublink')\n",
    "            return a_tag\n",
    "    except IndexError as e:\n",
    "        print(\"Error accessing main categories:\", e)\n",
    "        return []\n",
    "\n",
    "def access_sub_categories(subcategory_links):\n",
    "    try:\n",
    "        print ('Total Number of Sub-Categories within the Category :', len(subcategory_links))\n",
    "        subsub_categories = []  # Collect subsubcategory links\n",
    "        for j in range(len(subcategory_links)):\n",
    "            href_value = subcategory_links[j]['href']\n",
    "            print ('Sub-Category Link : ', href_value)\n",
    "            SubCate_soup = request_to_kaufland(href_value)\n",
    "        #    time.sleep(0.5)\n",
    "            try:\n",
    "                Sub_tag = SubCate_soup.find_all('a', class_='rd-link rd-link--navi-secondary rd-category-tree__anchor rd-category-tree__anchor--level-1')\n",
    "                if len(Sub_tag) == 0:\n",
    "                    first_page_products(SubCate_soup, PageNumber = 1)\n",
    "                else:\n",
    "                    subsub_categories.extend(Sub_tag)  # Collect subsubcategory links\n",
    "            except:\n",
    "                Sub_tag = SubCate_soup.find_all('a', class_='rd-link rd-link--navi-secondary rd-category-tree__anchor rd-category-tree__anchor--level-1')\n",
    "                subsub_categories.extend(Sub_tag)  # Collect subsubcategory links\n",
    "\n",
    "        return subsub_categories  # Return the list of subsubcategory links\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(\"Error accessing sub categories:\", e)\n",
    "        return []\n",
    "\n",
    "def access_subsub_categories(Subsub_categories_links):\n",
    "    try:\n",
    "        print ('Lenth of the Sub-Sub categories Links : ', len(Subsub_categories_links))\n",
    "        subsub_categories = []  # Collect subsubcategory links\n",
    "        if Subsub_categories_links:\n",
    "            for k in range(len(Subsub_categories_links)):\n",
    "                href_value = Subsub_categories_links[k]['href']\n",
    "                print('Sub-Sub Category Link: ', href_value)\n",
    "                Sub_SubCate_soup = request_to_kaufland(href_value)\n",
    "        #        time.sleep(0.5)\n",
    "                try:\n",
    "                    Subsub_tag = Sub_SubCate_soup.find_all('a', class_='rd-link rd-link--navi-secondary rd-category-tree__anchor rd-category-tree__anchor--level-2')\n",
    "                    if len(Subsub_tag) == 0:\n",
    "                        first_page_products(Sub_SubCate_soup, PageNumber = 1)\n",
    "                    else:\n",
    "                        subsub_categories.extend(Subsub_tag)  # Collect subsubcategory links\n",
    "                except:\n",
    "                    Subsub_tag = Sub_SubCate_soup.find_all('a', class_='rd-link rd-link--navi-secondary rd-category-tree__anchor rd-category-tree__anchor--level-2')\n",
    "                    subsub_categories.extend(Subsub_tag)  # Collect subsubcategory links\n",
    "        else:\n",
    "            print(\"No subcategories found.\")\n",
    "\n",
    "        return subsub_categories  # Return the list of subsubcategory links\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(\"Error accessing sub-sub categories:\", e)\n",
    "        return []\n",
    "\n",
    "def access_subsubsub_categories(SubSubSub_cat):\n",
    "    try:\n",
    "        for l in range(len(SubSubSub_cat)):\n",
    "            href_value = SubSubSub_cat[l]['href']\n",
    "            print('Sub-Sub-Sub Category Link: ', href_value)\n",
    "            Sub_SubCate_soup = request_to_kaufland(href_value)\n",
    "         #   time.sleep(0.5)\n",
    "            return Sub_SubCate_soup\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(\"Error accessing sub-sub-sub categories:\", e)\n",
    "        return []\n",
    "\n",
    "def first_page_products(ProductLists, PageNumber = 1):\n",
    "    try:\n",
    "        product_link = ProductLists.find_all('a', class_='product-link')\n",
    "        print ('Total Number of Products in Page', PageNumber,' is : ', len(product_link))\n",
    "        for ii in range(len(product_link)):  # len(product_link)\n",
    "            href_value = product_link[ii]['href']\n",
    "         #   print('Link of product:', main_url + href_value[1:])\n",
    "            product_soup = request_to_kaufland(main_url + href_value[1:])\n",
    "            product_linkXX = main_url + href_value[1:]\n",
    "            time.sleep(2.5)\n",
    "            Extract_Product_Info(product_soup, product_linkXX)\n",
    "\n",
    "       # search_query_tag = ProductLists.find('script', text=lambda text: text and 'window.__SEARCHFRONTEND__' in text)\n",
    "        search_query_tag = ProductLists.find('script', string=lambda text: text and 'window.__SEARCHFRONTEND__' in text)\n",
    "        input_string = str(search_query_tag)\n",
    "        url_pattern = r'url:\"(.*?)\"'\n",
    "        urls = re.findall(url_pattern, input_string)\n",
    "        number_pattern = r'\\\\u002Fcategory\\\\u002F(\\d+)\\\\'\n",
    "        numbers = []\n",
    "        for url in urls:\n",
    "            match = re.search(number_pattern, url)\n",
    "            if match:\n",
    "                number = match.group(1)\n",
    "                numbers.append(number)\n",
    "        \n",
    "        if PageNumber <= 4:   # Here we can adjust PageNumber upto any limit\n",
    "            try:\n",
    "                A = request_to_kaufland(main_url+'category/'+str(numbers[-1])+'/p'+str(PageNumber+1)+'/')\n",
    "                print ('Access to the Page Number : ', PageNumber+1, ' link is :', main_url+'category/'+str(numbers[-1])+'/p'+str(PageNumber+1)+'/')\n",
    "                first_page_products(A, PageNumber +1)\n",
    "            except:\n",
    "                print ('Error Due to PageNumber/Category....')   \n",
    "            '''\n",
    "            try:\n",
    "                B = request_to_kaufland(main_url+'topic/'+str(numbers[-1])+'/p'+str(PageNumber+1)+'/')\n",
    "            #    print ('Access to the Page Number : ', PageNumber+1, ' link is :', main_url+'category/'+str(numbers[-1])+'/p'+str(PageNumber+1)+'/')\n",
    "                first_page_products(B, PageNumber +1)\n",
    "            except:\n",
    "                print ('Error Due to PageNumber/Topic....')  \n",
    "            '''\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(\"Error accessing first page products:\", e)\n",
    "        return None\n",
    "\n",
    "def Extract_Product_Info(product_soup, product_linkXX):\n",
    "    data_to_save = {}  # Dictionary to store extracted data\n",
    "    product_name = product_soup.find('h1').text.strip()\n",
    "    data_to_save['Product_Name'] = product_name\n",
    "    data_to_save['Product_link'] = product_linkXX\n",
    "    categories = product_soup.find_all(class_='rd-breadcrumb__item')\n",
    "    count = 1\n",
    "    for category in categories:\n",
    "        data_to_save['Category_'+str(count)] = category.text.strip()\n",
    "        count += 1\n",
    "\n",
    "    try:\n",
    "        price = product_soup.find(class_='rd-price-information__price').text.replace('\\xa0', ' ').strip()        #rd-buybox-comparison__base-price\n",
    "        data_to_save['Price'] = price\n",
    "    except:\n",
    "        data_to_save['Price'] = None\n",
    "\n",
    "    description = product_soup.find(class_='rd-description-teaser__description-text').text\n",
    "    data_to_save['Description'] = description\n",
    "    images = str(product_soup.find_all(class_='swiper-slide'))\n",
    "    https_urls = re.findall(r'srcset=\"(https://.*?)\\\"', images)\n",
    "    count = 1\n",
    "    for url in https_urls:\n",
    "        data_to_save['Product_Image_'+str(count)] = url\n",
    "        count += 1\n",
    "    \n",
    "    #other_info = product_soup.find('script', text=lambda text: text and 'window.__PDPFRONTEND__' in text)\n",
    "    other_info = product_soup.find('script', string=lambda text: text and 'window.__PDPFRONTEND__' in text)\n",
    "    input_string = str(other_info)        \n",
    "\n",
    "    patterns = {\n",
    "        \"Verkehrsbezeichnung\": r'name:\"Verkehrsbezeichnung\",values:\\[{text:\"(.*?)\"',\n",
    "        \"Allergene\": r'name:\"Allergene\",values:\\[{text:\"(.*?)\"',\n",
    "        \"EAN\": r'name:\"EAN\",values:\\[{text:\"(.*?)\"',\n",
    "        \"Zutatenverzeichnis\": r'name:\"Zutatenverzeichnis\",values:\\[{text:\"(.*?)\"',\n",
    "        \"Nährwertdeklaration\": r'name:\"Nährwertdeklaration\",values:\\[{text:\"(.*?)\"',\n",
    "    }\n",
    "\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, input_string)\n",
    "        if match:\n",
    "            data_to_save[key] = match.group(1)\n",
    "        else:\n",
    "            data_to_save[key] = \"Not found\"\n",
    "    save_json(data_to_save)\n",
    "    \n",
    "def save_json(data):\n",
    "    try:\n",
    "        with open('justfinaltry.json', 'r') as json_file:\n",
    "            existing_data = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        existing_data = []\n",
    "\n",
    "    existing_data.append(data)\n",
    "\n",
    "    with open('justfinaltry.json', 'w') as json_file:\n",
    "        json.dump(existing_data, json_file, indent=4)\n",
    "\n",
    " #   print(\"Data appended to Kauland_Lebensmittlel.json\")\n",
    "\n",
    "soup = request_to_kaufland(main_url)\n",
    "if soup:\n",
    "    categories_link = [\"https://www.kaufland.de/lebensmittel/\",\n",
    "                       \"https://www.kaufland.de/koerperpflege-und-gesundheit/\"\n",
    "                      ]\n",
    "    subcategory_links = access_main_categories(categories_link)\n",
    "    Subsub_categories_links = access_sub_categories(subcategory_links)\n",
    "    print ('Problem1111111..............')\n",
    "    SubSubSub_cat = access_subsub_categories(Subsub_categories_links)\n",
    "    if SubSubSub_cat:\n",
    "        print ('Problem222222222..............')\n",
    "        ProductLists = access_subsubsub_categories(SubSubSub_cat)\n",
    "        product_soup = first_page_products(ProductLists)\n",
    "\n",
    "    else:\n",
    "        print ('Problem 3........................')\n",
    "else:\n",
    "    print(\"Failed to retrieve data from the main page.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeddded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada10c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd6cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
